{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e40243-c476-4cc7-88aa-5d264b9b5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create and Art with Neural style transfer on given image using deep learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "552f6b54-2d8b-4c9f-a80d-5e86fa4b6e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.2)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: namex in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: rich in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ayush\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\ayush\\\\Desktop\\\\CL3\\\\content.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m content_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# replace with your content image path\u001b[39;00m\n\u001b[0;32m     30\u001b[0m style_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstyle.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m      \u001b[38;5;66;03m# replace with your style image path\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m content_image \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_process_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m style_image \u001b[38;5;241m=\u001b[39m load_and_process_image(style_path)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Load VGG19 model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m, in \u001b[0;36mload_and_process_image\u001b[1;34m(path, max_dim)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_process_image\u001b[39m(path, max_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     long \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(img\u001b[38;5;241m.\u001b[39msize)\n\u001b[0;32m     11\u001b[0m     scale \u001b[38;5;241m=\u001b[39m max_dim \u001b[38;5;241m/\u001b[39m long\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ayush\\\\Desktop\\\\CL3\\\\content.jpg'"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow matplotlib pillow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_process_image(path, max_dim=512):\n",
    "    img = Image.open(path)\n",
    "    long = max(img.size)\n",
    "    scale = max_dim / long\n",
    "    img = img.resize((round(img.size[0] * scale), round(img.size[1] * scale)))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    return tf.keras.applications.vgg19.preprocess_input(img)\n",
    "\n",
    "# Function to deprocess image back to normal display\n",
    "def deprocess(img):\n",
    "    x = img.copy()\n",
    "    x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "# Load content and style images\n",
    "content_path = 'content.jpg'  # replace with your content image path\n",
    "style_path = 'style.jpg'      # replace with your style image path\n",
    "\n",
    "content_image = load_and_process_image(content_path)\n",
    "style_image = load_and_process_image(style_path)\n",
    "\n",
    "# Load VGG19 model\n",
    "vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "vgg.trainable = False\n",
    "\n",
    "# Define layers to use\n",
    "content_layers = ['block5_conv2']\n",
    "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "\n",
    "num_content_layers = len(content_layers)\n",
    "num_style_layers = len(style_layers)\n",
    "\n",
    "# Model to extract style and content\n",
    "def get_model():\n",
    "    outputs = [vgg.get_layer(name).output for name in style_layers + content_layers]\n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "    return model\n",
    "\n",
    "# Compute Gram matrix for style representation\n",
    "def gram_matrix(input_tensor):\n",
    "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "    input_shape = tf.shape(input_tensor)\n",
    "    num_locations = tf.cast(input_shape[1] * input_shape[2], tf.float32)\n",
    "    return result / num_locations\n",
    "\n",
    "# Extract features\n",
    "def get_features(model, content, style):\n",
    "    content_outputs = model(content)\n",
    "    style_outputs = model(style)\n",
    "\n",
    "    style_features = [gram_matrix(style_layer) for style_layer in style_outputs[:num_style_layers]]\n",
    "    content_features = [content_layer for content_layer in content_outputs[num_style_layers:]]\n",
    "    return style_features, content_features\n",
    "\n",
    "# Compute loss\n",
    "def compute_loss(model, loss_weights, init_image, gram_style_features, content_features):\n",
    "    style_weight, content_weight = loss_weights\n",
    "    model_outputs = model(init_image)\n",
    "\n",
    "    style_output_features = model_outputs[:num_style_layers]\n",
    "    content_output_features = model_outputs[num_style_layers:]\n",
    "\n",
    "    style_score = 0\n",
    "    content_score = 0\n",
    "\n",
    "    for target, comb in zip(gram_style_features, style_output_features):\n",
    "        style_score += tf.reduce_mean((gram_matrix(comb) - target) ** 2)\n",
    "\n",
    "    for target, comb in zip(content_features, content_output_features):\n",
    "        content_score += tf.reduce_mean((comb - target) ** 2)\n",
    "\n",
    "    style_score *= style_weight / num_style_layers\n",
    "    content_score *= content_weight / num_content_layers\n",
    "    total_loss = style_score + content_score\n",
    "    return total_loss\n",
    "\n",
    "# Run style transfer\n",
    "def run_style_transfer(content_path, style_path, num_iterations=1000, content_weight=1e3, style_weight=1e-2):\n",
    "    model = get_model()\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    content_image = load_and_process_image(content_path)\n",
    "    style_image = load_and_process_image(style_path)\n",
    "\n",
    "    gram_style_features, content_features = get_features(model, content_image, style_image)\n",
    "\n",
    "    init_image = tf.Variable(content_image, dtype=tf.float32)\n",
    "    opt = tf.optimizers.Adam(learning_rate=5)\n",
    "\n",
    "    best_loss, best_img = float('inf'), None\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = compute_loss(model, (style_weight, content_weight), init_image, gram_style_features, content_features)\n",
    "\n",
    "        grads = tape.gradient(loss, init_image)\n",
    "        opt.apply_gradients([(grads, init_image)])\n",
    "        init_image.assign(tf.clip_by_value(init_image, -103.939, 255.0 - 103.939))\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_img = init_image.numpy()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Loss: {loss.numpy()}\")\n",
    "\n",
    "    return deprocess(best_img)\n",
    "\n",
    "# Run and display\n",
    "output = run_style_transfer(content_path, style_path, num_iterations=500)\n",
    "plt.imshow(output)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aebcc6e-6994-4d75-90bd-5296e792c292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
